{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ealsticsearch tutorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import required modules\n",
    "import requests\n",
    "import json\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pprint(data):\n",
    "    print (json.dumps(data, sort_keys=True, indent=4, separators=(',', ': ')))\n",
    "\n",
    "def get_new_id():\n",
    "    return str(uuid.uuid1()).replace('-','')\n",
    "    \n",
    "def get(url,data):\n",
    "    return requests.get(url).json()\n",
    "\n",
    "def delete(url,data):\n",
    "    return requests.delete(url).json()\n",
    "\n",
    "def put(url, payload):\n",
    "    return requests.put(url,data= json.dumps(payload) ).json()\n",
    "\n",
    "def post(url, payload):\n",
    "    return requests.post(url,data= json.dumps(payload) ).json()\n",
    "\n",
    "services={\n",
    "    'GET':get,\n",
    "    'PUT':put,\n",
    "    'POST':post,\n",
    "    'DELETE':delete\n",
    "}\n",
    "\n",
    "def curl(url, method, payload={}):\n",
    "    return services[method](url,payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Elastic Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"cluster_name\": \"elasticsearch\",\n",
      "    \"cluster_uuid\": \"qSX_8o7OQ2KTv6RI2FDkOA\",\n",
      "    \"name\": \"DJ\",\n",
      "    \"tagline\": \"You Know, for Search\",\n",
      "    \"version\": {\n",
      "        \"build_hash\": \"d38a34e7b75af4e17ead16f156feffa432b22be3\",\n",
      "        \"build_snapshot\": false,\n",
      "        \"build_timestamp\": \"2016-12-07T16:28:56Z\",\n",
      "        \"lucene_version\": \"5.5.2\",\n",
      "        \"number\": \"2.4.3\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://127.0.0.1:9200'\n",
    "res = curl(url,'GET')\n",
    "pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Define index name and doc type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_name = \"bigdatairan\"\n",
    "doc_type = 'tweet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet={\n",
    "    'author':'Fartash Haghani',\n",
    "    'tweet_text':\"150tr gigabytes. That's the amount of information in a human body\",\n",
    "    'coordinate' : [3.09, 10.67],\n",
    "    'user_lang':'Fa',\n",
    "    'tweet_lang':'En',\n",
    "    'user_followers_count':203,\n",
    "    'gender':'male',\n",
    "    'race':'white'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new Index and index document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"_id\": \"070cc3b8c79811e6a28e88532e3b047f\",\n",
      "    \"_index\": \"bigdatairan\",\n",
      "    \"_shards\": {\n",
      "        \"failed\": 0,\n",
      "        \"successful\": 1,\n",
      "        \"total\": 2\n",
      "    },\n",
      "    \"_type\": \"tweet\",\n",
      "    \"_version\": 1,\n",
      "    \"created\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "documet_id=get_new_id()\n",
    "url = 'http://127.0.0.1:9200/{}/{}/{}'.format(index_name, doc_type, documet_id)\n",
    "res = curl(url,'PUT',tweet)\n",
    "pprint (res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getback the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"_id\": \"070cc3b8c79811e6a28e88532e3b047f\",\n",
      "    \"_index\": \"bigdatairan\",\n",
      "    \"_source\": {\n",
      "        \"author\": \"Fartash Haghani\",\n",
      "        \"coordinate\": [\n",
      "            3.09,\n",
      "            10.67\n",
      "        ],\n",
      "        \"gender\": \"male\",\n",
      "        \"race\": \"white\",\n",
      "        \"tweet_lang\": \"En\",\n",
      "        \"tweet_text\": \"150tr gigabytes. That's the amount of information in a human body\",\n",
      "        \"user_followers_count\": 203,\n",
      "        \"user_lang\": \"Fa\"\n",
      "    },\n",
      "    \"_type\": \"tweet\",\n",
      "    \"_version\": 1,\n",
      "    \"found\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://127.0.0.1:9200/{}/{}/{}'.format(index_name, doc_type, documet_id)\n",
    "res = curl(url,'GET')\n",
    "pprint (res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where is search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"_shards\": {\n",
      "        \"failed\": 0,\n",
      "        \"successful\": 5,\n",
      "        \"total\": 5\n",
      "    },\n",
      "    \"hits\": {\n",
      "        \"hits\": [\n",
      "            {\n",
      "                \"_id\": \"070cc3b8c79811e6a28e88532e3b047f\",\n",
      "                \"_index\": \"bigdatairan\",\n",
      "                \"_score\": 0.19178301,\n",
      "                \"_source\": {\n",
      "                    \"author\": \"Fartash Haghani\",\n",
      "                    \"coordinate\": [\n",
      "                        3.09,\n",
      "                        10.67\n",
      "                    ],\n",
      "                    \"gender\": \"male\",\n",
      "                    \"race\": \"white\",\n",
      "                    \"tweet_lang\": \"En\",\n",
      "                    \"tweet_text\": \"150tr gigabytes. That's the amount of information in a human body\",\n",
      "                    \"user_followers_count\": 203,\n",
      "                    \"user_lang\": \"Fa\"\n",
      "                },\n",
      "                \"_type\": \"tweet\"\n",
      "            }\n",
      "        ],\n",
      "        \"max_score\": 0.19178301,\n",
      "        \"total\": 1\n",
      "    },\n",
      "    \"timed_out\": false,\n",
      "    \"took\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query ='author:Haghani'\n",
    "url = 'http://127.0.0.1:9200/{}/{}/_search?q={}'.format(index_name, doc_type, query)\n",
    "res = curl(url,'GET')\n",
    "pprint (res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Search queries\n",
    "[query-dsl](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"_shards\": {\n",
      "        \"failed\": 0,\n",
      "        \"successful\": 5,\n",
      "        \"total\": 5\n",
      "    },\n",
      "    \"hits\": {\n",
      "        \"hits\": [\n",
      "            {\n",
      "                \"_id\": \"070cc3b8c79811e6a28e88532e3b047f\",\n",
      "                \"_index\": \"bigdatairan\",\n",
      "                \"_score\": 0.3986135,\n",
      "                \"_source\": {\n",
      "                    \"author\": \"Fartash Haghani\",\n",
      "                    \"coordinate\": [\n",
      "                        3.09,\n",
      "                        10.67\n",
      "                    ],\n",
      "                    \"gender\": \"male\",\n",
      "                    \"race\": \"white\",\n",
      "                    \"tweet_lang\": \"En\",\n",
      "                    \"tweet_text\": \"150tr gigabytes. That's the amount of information in a human body\",\n",
      "                    \"user_followers_count\": 203,\n",
      "                    \"user_lang\": \"Fa\"\n",
      "                },\n",
      "                \"_type\": \"tweet\"\n",
      "            }\n",
      "        ],\n",
      "        \"max_score\": 0.3986135,\n",
      "        \"total\": 1\n",
      "    },\n",
      "    \"timed_out\": false,\n",
      "    \"took\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query={\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        { \"match\": { \"author\": \"Fartash Haghani\" } },\n",
    "        { \"match\": { \"tweet_lang\": \"En\" } }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "url = 'http://127.0.0.1:9200/{}/{}/_search'.format(index_name, doc_type)\n",
    "res = curl(url,'POST',query)\n",
    "pprint (res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check current schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"bigdatairan\": {\n",
      "        \"mappings\": {\n",
      "            \"tweet\": {\n",
      "                \"properties\": {\n",
      "                    \"author\": {\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    \"coordinate\": {\n",
      "                        \"type\": \"double\"\n",
      "                    },\n",
      "                    \"gender\": {\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    \"race\": {\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    \"tweet_lang\": {\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    \"tweet_text\": {\n",
      "                        \"type\": \"string\"\n",
      "                    },\n",
      "                    \"user_followers_count\": {\n",
      "                        \"type\": \"long\"\n",
      "                    },\n",
      "                    \"user_lang\": {\n",
      "                        \"type\": \"string\"\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://127.0.0.1:9200/bigdatairan/_mapping'\n",
    "res = curl(url,'GET')\n",
    "pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"_id\": \"070cc3b8c79811e6a28e88532e3b047f\",\n",
      "    \"_index\": \"bigdatairan\",\n",
      "    \"_shards\": {\n",
      "        \"failed\": 0,\n",
      "        \"successful\": 1,\n",
      "        \"total\": 2\n",
      "    },\n",
      "    \"_type\": \"tweet\",\n",
      "    \"_version\": 2,\n",
      "    \"found\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://127.0.0.1:9200/{}/{}/{}'.format(index_name, doc_type, documet_id)\n",
    "res = curl(url,'DELETE')\n",
    "pprint (res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"error\": {\n",
      "        \"index\": \"bigdatairan\",\n",
      "        \"reason\": \"no such index\",\n",
      "        \"resource.id\": \"bigdatairan\",\n",
      "        \"resource.type\": \"index_or_alias\",\n",
      "        \"root_cause\": [\n",
      "            {\n",
      "                \"index\": \"bigdatairan\",\n",
      "                \"reason\": \"no such index\",\n",
      "                \"resource.id\": \"bigdatairan\",\n",
      "                \"resource.type\": \"index_or_alias\",\n",
      "                \"type\": \"index_not_found_exception\"\n",
      "            }\n",
      "        ],\n",
      "        \"type\": \"index_not_found_exception\"\n",
      "    },\n",
      "    \"status\": 404\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://127.0.0.1:9200/{}'.format(index_name)\n",
    "res = curl(url,'DELETE')\n",
    "pprint (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
